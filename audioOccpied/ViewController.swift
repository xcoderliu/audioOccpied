//
//  ViewController.swift
//  audioOccpied
//
//  Created by åˆ˜æ™ºæ°‘ on 2026/1/8.
//

import UIKit
import AVFoundation

class ViewController: UIViewController {
    
    private var audioPlayer: AVAudioPlayer?
    private var audioEngine: AVAudioEngine?
    private var playerNode: AVAudioPlayerNode?
    private var audioRecorder: AVAudioRecorder?
    
    private var delayTimer: Timer?
    private var remainingSeconds: Int = 0
    private var isInDelayCountdown: Bool = false
    
    private let playButton: UIButton = {
        let button = UIButton(type: .system)
        button.setTitle("å¼€å§‹ä¸­æ–­æµ‹è¯•", for: .normal)
        button.setTitle("åœæ­¢ä¸­æ–­", for: .selected)
        button.backgroundColor = .systemBlue
        button.setTitleColor(.white, for: .normal)
        button.titleLabel?.font = .boldSystemFont(ofSize: 18)
        button.layer.cornerRadius = 12
        button.translatesAutoresizingMaskIntoConstraints = false
        return button
    }()
    
    private let delaySwitch: UISwitch = {
        let sw = UISwitch()
        sw.isOn = false
        sw.translatesAutoresizingMaskIntoConstraints = false
        return sw
    }()
    
    private let delayLabel: UILabel = {
        let label = UILabel()
        label.text = "å»¶è¿Ÿ2ç§’å¼€å§‹"
        label.font = .systemFont(ofSize: 14, weight: .medium)
        label.translatesAutoresizingMaskIntoConstraints = false
        return label
    }()
    
    private let infoLabel: UILabel = {
        let label = UILabel()
        label.numberOfLines = 0
        label.font = .systemFont(ofSize: 14)
        label.textColor = .secondaryLabel
        label.translatesAutoresizingMaskIntoConstraints = false
        label.text = """
        ğŸ“± éŸ³é¢‘ä¸­æ–­æµ‹è¯•å·¥å…·
        
        åŠŸèƒ½ï¼šå¼ºåˆ¶ä¸­æ–­å…¶ä»–åº”ç”¨çš„éŸ³é¢‘æ’­æ”¾
        
        ä½¿ç”¨æ­¥éª¤ï¼š
        1. ç¡®ä¿ç›®æ ‡åº”ç”¨æ­£åœ¨æ’­æ”¾éŸ³é¢‘
        2. é€‰æ‹©æ˜¯å¦å»¶è¿Ÿ6ç§’å¼€å§‹
        3. ç‚¹å‡»"å¼€å§‹ä¸­æ–­"æŒ‰é’®
        4. è§‚å¯Ÿç›®æ ‡åº”ç”¨æ˜¯å¦æ”¶åˆ°ä¸­æ–­é€šçŸ¥
        
        æ—¥å¿—ä¼šæ˜¾ç¤ºä¸­æ–­é…ç½®è¯¦æƒ…
        """
        return label
    }()
    
    private let logTextView: UITextView = {
        let textView = UITextView()
        textView.font = .monospacedSystemFont(ofSize: 12, weight: .regular)
        textView.backgroundColor = .secondarySystemBackground
        textView.textColor = .label
        textView.layer.cornerRadius = 8
        textView.isEditable = false
        textView.translatesAutoresizingMaskIntoConstraints = false
        return textView
    }()

    override func viewDidLoad() {
        super.viewDidLoad()
        view.backgroundColor = .systemBackground
        title = "éŸ³é¢‘æŠ¢å æµ‹è¯•"
        
        setupUI()
        setupActions()
        setupNotifications()
        setupGestures()
        setupAudioSessionInterruptionMonitoring()
        
        log("âœ… æµ‹è¯•å·¥å…·å·²å¯åŠ¨")
    }
    
    deinit {
        NotificationCenter.default.removeObserver(self)
    }
    
    private func setupUI() {
        let logLabel = createLabel(text: "æ—¥å¿—è¾“å‡º:")
        
        view.addSubview(infoLabel)
        view.addSubview(delayLabel)
        view.addSubview(delaySwitch)
        view.addSubview(playButton)
        view.addSubview(logLabel)
        view.addSubview(logTextView)
        
        NSLayoutConstraint.activate([
            infoLabel.topAnchor.constraint(equalTo: view.safeAreaLayoutGuide.topAnchor, constant: 20),
            infoLabel.leadingAnchor.constraint(equalTo: view.leadingAnchor, constant: 20),
            infoLabel.trailingAnchor.constraint(equalTo: view.trailingAnchor, constant: -20),
            
            delayLabel.topAnchor.constraint(equalTo: infoLabel.bottomAnchor, constant: 25),
            delayLabel.leadingAnchor.constraint(equalTo: view.leadingAnchor, constant: 20),
            
            delaySwitch.centerYAnchor.constraint(equalTo: delayLabel.centerYAnchor),
            delaySwitch.trailingAnchor.constraint(equalTo: view.trailingAnchor, constant: -20),
            
            playButton.topAnchor.constraint(equalTo: delayLabel.bottomAnchor, constant: 25),
            playButton.centerXAnchor.constraint(equalTo: view.centerXAnchor),
            playButton.widthAnchor.constraint(equalToConstant: 260),
            playButton.heightAnchor.constraint(equalToConstant: 55),
            
            logLabel.topAnchor.constraint(equalTo: playButton.bottomAnchor, constant: 20),
            logLabel.leadingAnchor.constraint(equalTo: view.leadingAnchor, constant: 20),
            
            logTextView.topAnchor.constraint(equalTo: logLabel.bottomAnchor, constant: 8),
            logTextView.leadingAnchor.constraint(equalTo: view.leadingAnchor, constant: 20),
            logTextView.trailingAnchor.constraint(equalTo: view.trailingAnchor, constant: -20),
            logTextView.bottomAnchor.constraint(equalTo: view.safeAreaLayoutGuide.bottomAnchor, constant: -20)
        ])
    }
    
    private func createLabel(text: String) -> UILabel {
        let label = UILabel()
        label.text = text
        label.font = .systemFont(ofSize: 14, weight: .medium)
        label.translatesAutoresizingMaskIntoConstraints = false
        return label
    }
    
    private func setupActions() {
        playButton.addTarget(self, action: #selector(playButtonTapped), for: .touchUpInside)
    }
    
    private func setupGestures() {
        let doubleTap = UITapGestureRecognizer(target: self, action: #selector(clearLog))
        doubleTap.numberOfTapsRequired = 2
        logTextView.addGestureRecognizer(doubleTap)
    }
    
    private func setupNotifications() {
        // è¿™ä¸ªæµ‹è¯•åº”ç”¨æ˜¯ç”¨æ¥ä¸­æ–­å…¶ä»–åº”ç”¨çš„ï¼Œä¸éœ€è¦ç›‘å¬è‡ªå·±çš„ä¸­æ–­
        // åªç›‘å¬è·¯ç”±å˜åŒ–ç”¨äºè°ƒè¯•
        NotificationCenter.default.addObserver(
            self,
            selector: #selector(handleRouteChange),
            name: AVAudioSession.routeChangeNotification,
            object: nil
        )
        
        log("â„¹ï¸ æµ‹è¯•åº”ç”¨è§’è‰²ï¼šä¸­æ–­å…¶ä»–åº”ç”¨ï¼Œä¸ç›‘å¬è‡ªèº«ä¸­æ–­")
    }
    
    private func setupAudioSessionInterruptionMonitoring() {
        NotificationCenter.default.addObserver(
            self,
            selector: #selector(handleAudioSessionInterruption),
            name: AVAudioSession.interruptionNotification,
            object: nil
        )
    }
    
    @objc private func handleAudioSessionInterruption(notification: Notification) {
        guard let userInfo = notification.userInfo,
              let typeValue = userInfo[AVAudioSessionInterruptionTypeKey] as? UInt,
              let type = AVAudioSession.InterruptionType(rawValue: typeValue) else {
            return
        }

        switch type {
        case .began:
            log("âš ï¸ éŸ³é¢‘ä¼šè¯è¢«ä¸­æ–­")
        case .ended:
            log("âœ… éŸ³é¢‘ä¼šè¯ä¸­æ–­ç»“æŸ")
            startAudio()
        @unknown default:
            log("â“ æœªçŸ¥çš„éŸ³é¢‘ä¸­æ–­ç±»å‹")
        }
    }
    
    @objc private func playButtonTapped() {
        if isInDelayCountdown {
            // å¦‚æœåœ¨å€’è®¡æ—¶æœŸé—´å†æ¬¡ç‚¹å‡»ï¼Œå–æ¶ˆå€’è®¡æ—¶
            cancelDelayCountdown()
            log("â¹ï¸ å·²å–æ¶ˆå»¶è¿Ÿä¸­æ–­")
            return
        }
        
        if playButton.isSelected {
            stopAudio()
            playButton.isSelected = false
        } else {
            startAudio()
        }
    }
    
    @objc private func clearLog() {
        logTextView.text = ""
    }
    
    private func startAudio() {
        log("ğŸš€ å¼€å§‹éŸ³é¢‘ä¸­æ–­æµ‹è¯•")
        
        // æ£€æŸ¥å½“å‰æ˜¯å¦æœ‰å…¶ä»–éŸ³é¢‘åœ¨æ’­æ”¾
        let session = AVAudioSession.sharedInstance()
        if session.isOtherAudioPlaying {
            log("âœ… æ£€æµ‹åˆ°å…¶ä»–åº”ç”¨æ­£åœ¨æ’­æ”¾éŸ³é¢‘")
        } else {
            log("âš ï¸ æœªæ£€æµ‹åˆ°å…¶ä»–åº”ç”¨æ­£åœ¨æ’­æ”¾éŸ³é¢‘")
            log("   è¯·ç¡®ä¿ç›®æ ‡åº”ç”¨:")
            log("   1. è®¾ç½®äº†æ­£ç¡®çš„éŸ³é¢‘ä¼šè¯ç±»åˆ«")
            log("   2. è°ƒç”¨äº† setActive(true)")
            log("   3. å¼€å§‹æ’­æ”¾éŸ³é¢‘")
        }
        
        // æ ¹æ®å»¶è¿Ÿå¼€å…³å†³å®šæ˜¯å¦å»¶è¿Ÿæ‰§è¡Œ
        if delaySwitch.isOn {
            startDelayCountdown(seconds: 2)
        } else {
            playButton.isSelected = true
            forceInterruptionTest()
        }
    }
    
    private func startDelayCountdown(seconds: Int) {
        remainingSeconds = seconds
        isInDelayCountdown = true
        playButton.isSelected = true
        
        log("â° å»¶è¿Ÿ\(seconds)ç§’åå¼€å§‹ä¸­æ–­...")
        updateCountdownButtonTitle()
        
        // åˆ›å»ºå®šæ—¶å™¨å¹¶æ·»åŠ åˆ°RunLoopï¼Œç¡®ä¿åœ¨åå°ä¹Ÿèƒ½æ‰§è¡Œ
        delayTimer = Timer.scheduledTimer(withTimeInterval: 1.0, repeats: true) { [weak self] timer in
            guard let self = self else {
                timer.invalidate()
                return
            }
            
            self.remainingSeconds -= 1
            self.updateCountdownButtonTitle()
            
            if self.remainingSeconds <= 0 {
                timer.invalidate()
                self.delayTimer = nil
                self.isInDelayCountdown = false
                self.log("ğŸ¯ å»¶è¿Ÿç»“æŸï¼Œå¼€å§‹ä¸­æ–­æµ‹è¯•")
                self.forceInterruptionTest()
            }
        }
        
        // ç¡®ä¿å®šæ—¶å™¨åœ¨åå°æ¨¡å¼ä¸‹ä¹Ÿèƒ½ç»§ç»­è¿è¡Œ
        if let timer = delayTimer {
            RunLoop.main.add(timer, forMode: .common)
        }
    }
    
    private func cancelDelayCountdown() {
        delayTimer?.invalidate()
        delayTimer = nil
        isInDelayCountdown = false
        remainingSeconds = 0
        playButton.isSelected = false
        playButton.setTitle("å¼€å§‹ä¸­æ–­æµ‹è¯•", for: .normal)
        playButton.setTitle("åœæ­¢ä¸­æ–­", for: .selected)
    }
    
    private func updateCountdownButtonTitle() {
        if isInDelayCountdown && remainingSeconds > 0 {
            playButton.setTitle("å–æ¶ˆ (\(remainingSeconds)s)", for: .normal)
            playButton.setTitle("å–æ¶ˆ (\(remainingSeconds)s)", for: .selected)
        } else {
            playButton.setTitle("å¼€å§‹ä¸­æ–­æµ‹è¯•", for: .normal)
            playButton.setTitle("åœæ­¢ä¸­æ–­", for: .selected)
        }
    }
    
    private func stopAudio() {
        // ç§»é™¤ tap
        if let engine = audioEngine {
            engine.inputNode.removeTap(onBus: 0)
        }
        
        audioPlayer?.stop()
        audioPlayer = nil
        
        audioEngine?.stop()
        audioEngine = nil
        playerNode = nil
        
        audioRecorder?.stop()
        audioRecorder = nil
        
        do {
            try AVAudioSession.sharedInstance().setActive(false, options: .notifyOthersOnDeactivation)
            log("âœ… éŸ³é¢‘ä¼šè¯å·²åœæ­¢ï¼ˆé€šçŸ¥å…¶ä»–åº”ç”¨ï¼‰")
        } catch {
            log("âŒ åœæ­¢éŸ³é¢‘ä¼šè¯å¤±è´¥: \(error.localizedDescription)")
        }
    }
    
    // MARK: - éŸ³é¢‘æ’­æ”¾
    private func playAudioWithPlayer(volume: Float = 1, loops: Int = -1, description: String = "Cå¤§è°ƒæ—‹å¾‹") -> Bool {
        guard let audioFileURL = generateTestAudioFile() else {
            log("âŒ ç”Ÿæˆæµ‹è¯•éŸ³é¢‘æ–‡ä»¶å¤±è´¥")
            return false
        }
        
        do {
            audioPlayer = try AVAudioPlayer(contentsOf: audioFileURL)
            audioPlayer?.delegate = self
            audioPlayer?.numberOfLoops = loops
            audioPlayer?.volume = volume
            
            let success = audioPlayer?.play() ?? false
            if success {
                log("âœ… AVAudioPlayer å¼€å§‹æ’­æ”¾ï¼ˆ\(description)ï¼‰")
                log("   éŸ³é‡: \(volume)")
                log("   æ˜¯å¦æ­£åœ¨æ’­æ”¾: \(audioPlayer?.isPlaying ?? false)")
                
                // æ‰“å°å½“å‰éŸ³é¢‘ä¼šè¯é…ç½®
                let currentSession = AVAudioSession.sharedInstance()
                logAudioSessionDetails(currentSession)
                
                // å»¶è¿Ÿæ£€æŸ¥éŸ³é¢‘ä¼šè¯çŠ¶æ€
                DispatchQueue.main.asyncAfter(deadline: .now() + 0.5) {
                    self.logAudioSessionStatus()
                }
                return true
            } else {
                log("âŒ AVAudioPlayer play() è¿”å› false")
                return false
            }
        } catch {
            log("âŒ AVAudioPlayer åˆå§‹åŒ–å¤±è´¥: \(error.localizedDescription)")
            return false
        }
    }
    
    
    
    
    // MARK: - å¼ºåˆ¶ä¸­æ–­æµ‹è¯•
    private func forceInterruptionTest() {
        log("ğŸš€ å¼€å§‹å¼ºåˆ¶ä¸­æ–­æµ‹è¯•")
        log("   ç›®æ ‡ï¼šå¼ºåˆ¶ä¸­æ–­ä½¿ç”¨ .mixWithOthers çš„ä¸»ç«¯åº”ç”¨")
        
        // é¦–å…ˆæ’­æ”¾éŸ³ä¹
        playAudioForInterruptionTest()
        log("ğŸµ å¼€å§‹æ’­æ”¾æµ‹è¯•éŸ³ä¹ï¼ˆCå¤§è°ƒæ—‹å¾‹ï¼‰")
        
        // æ–¹æ³•1ï¼šä½¿ç”¨é«˜ä¼˜å…ˆçº§çš„éŸ³é¢‘æ¨¡å¼ï¼ˆåªé…ç½®ï¼Œä¸é‡å¤æ’­æ”¾éŸ³ä¹ï¼‰
        forceInterruptionWithHighPriorityMode()
        
        // æ–¹æ³•2ï¼šä½¿ç”¨ç‰¹å®šçš„éŸ³é¢‘é…ç½®ï¼ˆåªé…ç½®ï¼Œä¸é‡å¤æ’­æ”¾éŸ³ä¹ï¼‰
        DispatchQueue.main.asyncAfter(deadline: .now() + 0.5) {
            self.forceInterruptionWithSpecificConfiguration()
        }
        
        // æ–¹æ³•3ï¼šæ¨¡æ‹Ÿç”µè¯æ¥ç”µåœºæ™¯ï¼ˆåªé…ç½®ï¼Œä¸é‡å¤æ’­æ”¾éŸ³ä¹ï¼‰
        DispatchQueue.main.asyncAfter(deadline: .now() + 1.0) {
            self.simulatePhoneCallScenario()
        }
    }
    
    private func forceInterruptionWithHighPriorityMode() {
        log("ğŸ“ æ–¹æ³•1ï¼šä½¿ç”¨é«˜ä¼˜å…ˆçº§éŸ³é¢‘æ¨¡å¼")
        
        do {
            let session = AVAudioSession.sharedInstance()
            
            // ä½¿ç”¨ .voiceChat æ¨¡å¼ï¼Œè¿™æ˜¯ç³»ç»Ÿä¼˜å…ˆçº§æœ€é«˜çš„æ¨¡å¼ä¹‹ä¸€
            // å³ä½¿å…¶ä»–åº”ç”¨ä½¿ç”¨ .mixWithOthersï¼Œä¹Ÿä¼šè¢«ä¸­æ–­
            try session.setCategory(.playAndRecord, mode: .voiceChat, options: [])
            
            // æ¿€æ´»æ—¶ä½¿ç”¨ .notifyOthersOnDeactivationï¼Œè¿™ä¼šé€šçŸ¥å…¶ä»–åº”ç”¨
            try session.setActive(true, options: .notifyOthersOnDeactivation)
            
            log("âœ… é…ç½®ä¸º .playAndRecord + .voiceChat æ¨¡å¼")
            log("   è¿™æ˜¯ç³»ç»Ÿä¼˜å…ˆçº§æœ€é«˜çš„éŸ³é¢‘æ¨¡å¼ä¹‹ä¸€")
            log("   åº”è¯¥èƒ½å¼ºåˆ¶ä¸­æ–­å…¶ä»–åº”ç”¨çš„éŸ³é¢‘")
            
        } catch {
            log("âŒ é…ç½®é«˜ä¼˜å…ˆçº§æ¨¡å¼å¤±è´¥: \(error.localizedDescription)")
        }
    }
    
    private func forceInterruptionWithSpecificConfiguration() {
        log("ğŸ¯ æ–¹æ³•2ï¼šä½¿ç”¨ç‰¹å®šé…ç½®å¼ºåˆ¶ä¸­æ–­")
        
        do {
            let session = AVAudioSession.sharedInstance()
            
            // ä½¿ç”¨ .videoChat æ¨¡å¼ï¼Œè¿™ä¹Ÿæ˜¯é«˜ä¼˜å…ˆçº§æ¨¡å¼
            // æ·»åŠ  .defaultToSpeaker å’Œ .allowBluetooth
            let options: AVAudioSession.CategoryOptions = [
                .defaultToSpeaker,
                .allowBluetooth,
                .allowBluetoothA2DP
            ]
            
            try session.setCategory(.playAndRecord, mode: .videoChat, options: options)
            try session.setActive(true, options: .notifyOthersOnDeactivation)
            
            log("âœ… é…ç½®ä¸º .playAndRecord + .videoChat æ¨¡å¼")
            log("   é€‰é¡¹: defaultToSpeaker, allowBluetooth, allowBluetoothA2DP")
            log("   è¿™ç§é…ç½®å¸¸ç”¨äºè§†é¢‘é€šè¯ï¼Œä¼˜å…ˆçº§å¾ˆé«˜")
            
        } catch {
            log("âŒ é…ç½®ç‰¹å®šæ¨¡å¼å¤±è´¥: \(error.localizedDescription)")
        }
    }
    
    private func simulatePhoneCallScenario() {
        log("ğŸ“± æ–¹æ³•3ï¼šæ¨¡æ‹Ÿç”µè¯æ¥ç”µåœºæ™¯ï¼ˆä½¿ç”¨éº¦å…‹é£ï¼‰")
        
        do {
            let session = AVAudioSession.sharedInstance()
            
            // æ¨¡æ‹Ÿç”µè¯åœºæ™¯ï¼šä½¿ç”¨ .voiceChat æ¨¡å¼ + ç‰¹å®šé€‰é¡¹
            let options: AVAudioSession.CategoryOptions = [
                .allowBluetooth,
                .allowAirPlay,
                .allowBluetoothA2DP,
                .defaultToSpeaker  // ç”µè¯é€šå¸¸ä½¿ç”¨æ‰¬å£°å™¨
            ]
            
            try session.setCategory(.playAndRecord, mode: .voiceChat, options: options)
            
            // ä½¿ç”¨ .notifyOthersOnDeactivation æ¿€æ´»
            try session.setActive(true, options: .notifyOthersOnDeactivation)
            
            log("âœ… æ¨¡æ‹Ÿç”µè¯æ¥ç”µé…ç½®å®Œæˆ")
            log("   é…ç½®: .playAndRecord + .voiceChat")
            log("   é€‰é¡¹: allowBluetooth, allowAirPlay, allowBluetoothA2DP, defaultToSpeaker")
            log("   è¿™ç§é…ç½®æœ€æ¥è¿‘çœŸå®çš„ç”µè¯ä¸­æ–­åœºæ™¯")
            
            // æ£€æŸ¥ç³»ç»ŸçŠ¶æ€
            if session.secondaryAudioShouldBeSilencedHint {
                log("âœ… ç³»ç»Ÿæç¤ºï¼šå…¶ä»–éŸ³é¢‘åº”è¯¥è¢«é™éŸ³")
            }
            
            if session.isOtherAudioPlaying {
                log("âœ… æ£€æµ‹åˆ°å…¶ä»–åº”ç”¨æ­£åœ¨æ’­æ”¾éŸ³é¢‘")
                log("   åº”è¯¥ä¼šæ”¶åˆ°ä¸­æ–­é€šçŸ¥")
            }
            
            // å…³é”®ï¼šå¼€å§‹ä½¿ç”¨éº¦å…‹é£ï¼ˆæ¨¡æ‹Ÿé€šè¯ï¼‰
            startMicrophoneForPhoneCall()
            
            // åŒæ—¶æ’­æ”¾ä¸€äº›éŸ³é¢‘ï¼ˆæ¨¡æ‹Ÿé€šè¯å£°éŸ³ï¼‰
            playPhoneCallAudio()
            
        } catch {
            log("âŒ æ¨¡æ‹Ÿç”µè¯åœºæ™¯å¤±è´¥: \(error.localizedDescription)")
        }
    }
    
    private func startMicrophoneForPhoneCall() {
        log("ğŸ¤ å¼€å§‹ä½¿ç”¨éº¦å…‹é£ï¼ˆæ¨¡æ‹Ÿé€šè¯ï¼‰")
        
        // åˆ›å»ºæ–°çš„éŸ³é¢‘å¼•æ“ç”¨äºéº¦å…‹é£é‡‡é›†
        let phoneCallEngine = AVAudioEngine()
        
        do {
            let inputNode = phoneCallEngine.inputNode
            let inputFormat = inputNode.outputFormat(forBus: 0)
            
            log("ğŸ“¡ éº¦å…‹é£é…ç½®:")
            log("   é‡‡æ ·ç‡: \(inputFormat.sampleRate) Hz")
            log("   å£°é“æ•°: \(inputFormat.channelCount)")
            
            // å®‰è£… tap é‡‡é›†éº¦å…‹é£æ•°æ®ï¼ˆæ¨¡æ‹Ÿé€šè¯ä¸­çš„è¯­éŸ³è¾“å…¥ï¼‰
            inputNode.installTap(onBus: 0, bufferSize: 1024, format: inputFormat) { [weak self] (buffer, time) in
                // æ¨¡æ‹Ÿå¤„ç†é€šè¯è¯­éŸ³æ•°æ®
                let channelData = buffer.floatChannelData
                let frameLength = Int(buffer.frameLength)
                
                // è®¡ç®—éŸ³é‡ï¼ˆæ¨¡æ‹Ÿé€šè¯ä¸­çš„è¯­éŸ³æ´»åŠ¨ï¼‰
                if let data = channelData?.pointee {
                    var sum: Float = 0
                    for i in 0..<frameLength {
                        let value = data[i]
                        sum += value * value
                    }
                    let rms = sqrt(sum / Float(frameLength))
                    
                    // å®šæœŸè®°å½•éŸ³é‡ï¼ˆæ¨¡æ‹Ÿé€šè¯ä¸­çš„è¯­éŸ³æ£€æµ‹ï¼‰
                    if Int(time.sampleTime) % Int(inputFormat.sampleRate) == 0 {
                        DispatchQueue.main.async {
                            self?.log("ğŸ“ é€šè¯ä¸­... è¯­éŸ³ç”µå¹³: \(String(format: "%.4f", rms))")
                        }
                    }
                }
            }
            
            // å¯åŠ¨éŸ³é¢‘å¼•æ“
            try phoneCallEngine.start()
            
            // ä¿å­˜å¼•ç”¨
            self.audioEngine = phoneCallEngine
            
            log("âœ… éº¦å…‹é£å·²å¯åŠ¨ï¼ˆæ¨¡æ‹Ÿé€šè¯ä¸­ï¼‰")
            log("   è¿™ä¼šå¼ºåˆ¶å ç”¨éº¦å…‹é£è®¾å¤‡")
            log("   ä½¿ç”¨éº¦å…‹é£çš„åº”ç”¨åº”è¯¥ä¼šæ”¶åˆ°ä¸­æ–­")
            
        } catch {
            log("âŒ å¯åŠ¨éº¦å…‹é£å¤±è´¥: \(error.localizedDescription)")
        }
    }
    
    private func playPhoneCallAudio() {
        log("ğŸ”Š æ’­æ”¾é€šè¯éŸ³é¢‘ï¼ˆæ¨¡æ‹Ÿå¯¹æ–¹å£°éŸ³ï¼‰")
        
        // ç”Ÿæˆä¸€ä¸ªç®€å•çš„é€šè¯éŸ³é¢‘ï¼ˆæ¨¡æ‹Ÿå¯¹æ–¹è¯´è¯ï¼‰
        let phoneCallEngine = AVAudioEngine()
        let playerNode = AVAudioPlayerNode()
        
        phoneCallEngine.attach(playerNode)
        
        let format = phoneCallEngine.mainMixerNode.outputFormat(forBus: 0)
        phoneCallEngine.connect(playerNode, to: phoneCallEngine.mainMixerNode, format: format)
        
        // ç”Ÿæˆä¸€ä¸ªç®€å•çš„è¯­éŸ³é¢‘ç‡çš„æ­£å¼¦æ³¢ï¼ˆæ¨¡æ‹Ÿé€šè¯å£°éŸ³ï¼‰
        if let buffer = generatePhoneCallBuffer(format: format) {
            playerNode.scheduleBuffer(buffer, at: nil, options: .loops)
        }
        
        do {
            try phoneCallEngine.start()
            playerNode.play()
            
            log("âœ… é€šè¯éŸ³é¢‘å·²å¼€å§‹æ’­æ”¾")
            log("   é¢‘ç‡: 300-800Hzï¼ˆæ¨¡æ‹Ÿè¯­éŸ³èŒƒå›´ï¼‰")
            log("   éŸ³é‡: 90%")
            
        } catch {
            log("âŒ æ’­æ”¾é€šè¯éŸ³é¢‘å¤±è´¥: \(error.localizedDescription)")
        }
    }
    
    private func generatePhoneCallBuffer(format: AVAudioFormat) -> AVAudioPCMBuffer? {
        let sampleRate = format.sampleRate
        let duration = 2.0  // 2ç§’çš„ç¼“å†²åŒº
        let frameCount = AVAudioFrameCount(sampleRate * duration)
        
        guard let buffer = AVAudioPCMBuffer(pcmFormat: format, frameCapacity: frameCount) else {
            return nil
        }
        
        buffer.frameLength = frameCount
        
        let channels = Int(format.channelCount)
        let floatChannelData = buffer.floatChannelData
        
        // ä½¿ç”¨å˜åŒ–çš„é¢‘ç‡æ¨¡æ‹Ÿè¯­éŸ³
        let baseFrequency = 300.0
        let frequencyRange = 500.0  // 300-800Hz
        
        for frame in 0..<Int(frameCount) {
            // éšæ—¶é—´å˜åŒ–çš„é¢‘ç‡ï¼ˆæ¨¡æ‹Ÿè¯­éŸ³çš„éŸ³è°ƒå˜åŒ–ï¼‰
            let time = Double(frame) / sampleRate
            let frequency = baseFrequency + (frequencyRange * (0.5 + 0.5 * sin(2.0 * .pi * 2.0 * time)))
            
            let value = sin(2.0 * .pi * frequency * Double(frame) / sampleRate)
            
            // åº”ç”¨åŒ…ç»œä½¿å£°éŸ³æ›´è‡ªç„¶
            let envelope: Float
            let frameProgress = Float(frame) / Float(frameCount)
            if frameProgress < 0.1 {
                envelope = frameProgress / 0.1  // æ·¡å…¥
            } else if frameProgress > 0.9 {
                envelope = (1.0 - frameProgress) / 0.1  // æ·¡å‡º
            } else {
                envelope = 1.0
            }
            
            let amplitude: Float = 1 * envelope  
            
            for channel in 0..<channels {
                floatChannelData?[channel][frame] = Float(value) * amplitude
            }
        }
        
        return buffer
    }
    
    private func playAudioForInterruptionTest() {
        let success = playAudioWithPlayer(volume: 1.0, loops: -1, description: "æµ‹è¯•éŸ³ä¹ï¼ˆCå¤§è°ƒæ—‹å¾‹ï¼‰")
        if success {
            log("âœ… å¼€å§‹æ’­æ”¾æµ‹è¯•éŸ³é¢‘")
            log("   éŸ³é‡: 100%")
            log("   å¾ªç¯æ’­æ”¾: æ˜¯")
        }
    }
    
    
    // MARK: - éŸ³é¢‘ä¼šè¯é…ç½®
    private func configureAudioSession(
        category: AVAudioSession.Category,
        mode: AVAudioSession.Mode = .default,
        options: AVAudioSession.CategoryOptions = [],
        activateOptions: AVAudioSession.SetActiveOptions = []
    ) throws {
        let session = AVAudioSession.sharedInstance()
        
        // å…ˆåœç”¨æ—§ä¼šè¯
        try session.setActive(false, options: .notifyOthersOnDeactivation)
        
        // é…ç½®æ–°çš„éŸ³é¢‘ä¼šè¯
        try session.setCategory(category, mode: mode, options: options)
        
        // æ¿€æ´»éŸ³é¢‘ä¼šè¯
        try session.setActive(true, options: activateOptions)
        
        // æ‰“å°è¯¦ç»†é…ç½®å‚æ•°
        logAudioSessionDetails(session)
    }
    
    // MARK: - éŸ³é¢‘ç”Ÿæˆ
    private func generateTestAudioFile() -> URL? {
        let fileURL = FileManager.default.temporaryDirectory.appendingPathComponent("test_music.m4a")
        
        if FileManager.default.fileExists(atPath: fileURL.path) {
            return fileURL
        }
        
        let sampleRate = 44100.0
        let duration = 4.0  // å»¶é•¿åˆ°4ç§’ä»¥æ’­æ”¾å®Œæ•´æ—‹å¾‹
        
        let settings: [String: Any] = [
            AVFormatIDKey: kAudioFormatMPEG4AAC,
            AVSampleRateKey: sampleRate,
            AVNumberOfChannelsKey: 1,
            AVEncoderAudioQualityKey: AVAudioQuality.high.rawValue
        ]
        
        do {
            let audioFile = try AVAudioFile(forWriting: fileURL, settings: settings)
            let format = audioFile.processingFormat
            
            if let buffer = generateSimpleMusicBuffer(duration: duration, format: format) {
                try audioFile.write(from: buffer)
                log("âœ… ç”Ÿæˆç®€å•éŸ³ä¹æ–‡ä»¶æˆåŠŸï¼ˆCå¤§è°ƒæ—‹å¾‹ï¼‰")
                return fileURL
            }
        } catch {
            log("âŒ ç”ŸæˆéŸ³ä¹æ–‡ä»¶å¤±è´¥: \(error.localizedDescription)")
        }
        
        return nil
    }
    
    private func generateSimpleMusicBuffer(duration: Double, format: AVAudioFormat) -> AVAudioPCMBuffer? {
        let sampleRate = format.sampleRate
        let frameCount = AVAudioFrameCount(sampleRate * duration)
        
        guard let buffer = AVAudioPCMBuffer(pcmFormat: format, frameCapacity: frameCount) else {
            return nil
        }
        
        buffer.frameLength = frameCount
        
        let channels = Int(format.channelCount)
        let floatChannelData = buffer.floatChannelData
        
        // Cå¤§è°ƒéŸ³é˜¶é¢‘ç‡ (C4, D4, E4, F4, G4, A4, B4, C5)
        let cMajorScale: [Double] = [
            261.63,  // C4
            293.66,  // D4
            329.63,  // E4
            349.23,  // F4
            392.00,  // G4
            440.00,  // A4
            493.88,  // B4
            523.25   // C5
        ]
        
        // æ¯ä¸ªéŸ³ç¬¦çš„æŒç»­æ—¶é—´ï¼ˆç§’ï¼‰
        let noteDuration = duration / Double(cMajorScale.count)
        let framesPerNote = Int(sampleRate * noteDuration)
        
        for noteIndex in 0..<cMajorScale.count {
            let frequency = cMajorScale[noteIndex]
            let startFrame = noteIndex * framesPerNote
            let endFrame = min(startFrame + framesPerNote, Int(frameCount))
            
            for frame in startFrame..<endFrame {
                // è®¡ç®—å½“å‰å¸§åœ¨éŸ³ç¬¦ä¸­çš„ä½ç½®ï¼ˆç”¨äºæ·¡å…¥æ·¡å‡ºï¼‰
                let noteFrame = frame - startFrame
                let noteProgress = Double(noteFrame) / Double(framesPerNote)
                
                // æ·¡å…¥æ·¡å‡ºåŒ…ç»œ
                var envelope: Float = 1.0
                if noteProgress < 0.1 {
                    // æ·¡å…¥
                    envelope = Float(noteProgress / 0.1)
                } else if noteProgress > 0.9 {
                    // æ·¡å‡º
                    envelope = Float((1.0 - noteProgress) / 0.1)
                }
                
                // ç”Ÿæˆæ­£å¼¦æ³¢
                let value = sin(2.0 * .pi * frequency * Double(frame) / sampleRate)
                
                // åº”ç”¨åŒ…ç»œ
                let amplitude: Float = 1 * envelope
                
                for channel in 0..<channels {
                    floatChannelData?[channel][frame] = Float(value) * amplitude
                }
            }
        }
        
        // å¡«å……å‰©ä½™å¸§ï¼ˆå¦‚æœæœ‰ï¼‰
        let totalNotesFrames = cMajorScale.count * framesPerNote
        if totalNotesFrames < Int(frameCount) {
            for frame in totalNotesFrames..<Int(frameCount) {
                for channel in 0..<channels {
                    floatChannelData?[channel][frame] = 0.0
                }
            }
        }
        
        return buffer
    }
    
    @objc private func handleRouteChange(notification: Notification) {
        guard let userInfo = notification.userInfo,
              let reasonValue = userInfo[AVAudioSessionRouteChangeReasonKey] as? UInt,
              let reason = AVAudioSession.RouteChangeReason(rawValue: reasonValue) else {
            return
        }
        
        let reasonText: String
        switch reason {
        case .oldDeviceUnavailable:
            reasonText = "æ—§è®¾å¤‡ä¸å¯ç”¨"
        case .newDeviceAvailable:
            reasonText = "æ–°è®¾å¤‡å¯ç”¨"
        case .categoryChange:
            reasonText = "ç±»åˆ«å˜åŒ–"
        default:
            reasonText = "å…¶ä»–åŸå› "
        }
        
        log("ğŸ”„ éŸ³é¢‘è·¯ç”±å˜åŒ–: \(reasonText)")
    }
    
    private func logAudioSessionDetails(_ session: AVAudioSession) {
        let currentCategory = session.category.rawValue
        let currentMode = session.mode.rawValue
        let options = session.categoryOptions
        
        var optionsDesc = [String]()
        if options.contains(.mixWithOthers) { optionsDesc.append("mixWithOthers") }
        if options.contains(.duckOthers) { optionsDesc.append("duckOthers") }
        if options.contains(.allowBluetooth) { optionsDesc.append("allowBluetooth") }
        if options.contains(.defaultToSpeaker) { optionsDesc.append("defaultToSpeaker") }
        if options.contains(.interruptSpokenAudioAndMixWithOthers) { optionsDesc.append("interruptSpokenAudioAndMixWithOthers") }
        if options.contains(.allowBluetoothA2DP) { optionsDesc.append("allowBluetoothA2DP") }
        if options.contains(.allowAirPlay) { optionsDesc.append("allowAirPlay") }
        if #available(iOS 14.5, *) {
            if options.contains(.overrideMutedMicrophoneInterruption) { optionsDesc.append("overrideMutedMicrophoneInterruption") }
        }
        
        let optionsStr = optionsDesc.isEmpty ? "[]" : "[\(optionsDesc.joined(separator: ", "))]"
        log("ğŸ“Š éŸ³é¢‘ä¼šè¯è¯¦ç»†é…ç½®:")
        log("   category: \(currentCategory)")
        log("   mode: \(currentMode)")
        log("   options: \(optionsStr)")
    }
    
    private func logAudioSessionStatus() {
        let session = AVAudioSession.sharedInstance()
        log("ğŸ“Š éŸ³é¢‘ä¼šè¯çŠ¶æ€æ£€æŸ¥:")
        log("   category: \(session.category.rawValue)")
        log("   mode: \(session.mode.rawValue)")
        log("   isOtherAudioPlaying: \(session.isOtherAudioPlaying)")
        log("   secondaryAudioShouldBeSilencedHint: \(session.secondaryAudioShouldBeSilencedHint)")
        
        if let route = session.currentRoute.outputs.first {
            log("   è¾“å‡ºè®¾å¤‡: \(route.portType.rawValue)")
        }
    }
    
    private func log(_ message: String) {
        let timestamp = DateFormatter.localizedString(from: Date(), dateStyle: .none, timeStyle: .medium)
        let logMessage = "[\(timestamp)] \(message)\n"
        
        DispatchQueue.main.async {
            self.logTextView.text = logMessage + self.logTextView.text
        }
        
        print(logMessage)
    }
}

// MARK: - AVAudioPlayerDelegate
extension ViewController: AVAudioPlayerDelegate {
    func audioPlayerDidFinishPlaying(_ player: AVAudioPlayer, successfully flag: Bool) {
        log("ğŸµ AVAudioPlayer æ’­æ”¾ç»“æŸ: \(flag)")
    }
    
    func audioPlayerDecodeErrorDidOccur(_ player: AVAudioPlayer, error: Error?) {
        log("âŒ AVAudioPlayer è§£ç é”™è¯¯: \(error?.localizedDescription ?? "unknown")")
    }
}

